name: Generate GrowliZard Pok√©mon Sheet

on:
  workflow_dispatch:
  schedule:
    - cron: "0 12 * * *"

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install Dependencies and Browsers
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests beautifulsoup4 Pillow fpdf2 replicate playwright
          python -m playwright install --with-deps
          
      - name: Scrape TCGplayer Data
        run: |
          python << 'EOF'
          import pandas as pd
          from bs4 import BeautifulSoup
          import re
          from playwright.sync_api import sync_playwright
          import time

          BASE_URL = "https://www.tcgplayer.com/search/pokemon/sv09-shrouded-fable?productLineName=pokemon&setName=sv09-shrouded-fable&view=grid"
          TARGET_SET_NAME = "Shrouded Fable" # Define our target set
          
          all_cards_list = []
          page_number = 1

          print(f"Starting scraper for set '{TARGET_SET_NAME}' with pagination and scrolling...")

          with sync_playwright() as p:
              browser = p.chromium.launch(headless=True)
              page = browser.new_page()

              while True:
                  paginated_url = f"{BASE_URL}&page={page_number}"
                  print(f"Scraping URL: {paginated_url}")
                  
                  html_content = ""
                  try:
                      page.goto(paginated_url, wait_until="domcontentloaded", timeout=60000)
                      page.wait_for_selector("div.search-result, div.search-feedback", timeout=30000)
                      
                      print("Scrolling down to trigger lazy-loaded images...")
                      last_height = page.evaluate("document.body.scrollHeight")
                      while True:
                          page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
                          time.sleep(1) 
                          new_height = page.evaluate("document.body.scrollHeight")
                          if new_height == last_height:
                              break
                          last_height = new_height
                      
                      html_content = page.content()

                  except Exception as e:
                      print(f"!!! FAILED during Playwright browser operation on page {page_number}: {e}")
                      break

                  soup = BeautifulSoup(html_content, "html.parser")
                  search_results = soup.find_all("div", class_="search-result")

                  if not search_results:
                    print(f"No more search results found on page {page_number}. Ending scrape.")
                    break
                  
                  print(f"Found {len(search_results)} card results on page {page_number}. Now parsing and filtering...")

                  for card in search_results:
                      # Scrape all details, including the set name for verification
                      name_tag = card.find("span", class_="product-card__title")
                      price_tag = card.find("span", class_="product-card__market-price--value")
                      image_tag = card.find("img")
                      set_name_tag = card.find("h4", class_="product-card__set-name") # NEW: Find the set name tag

                      name = name_tag.text.strip() if name_tag else None
                      price_text = price_tag.text.strip() if price_tag else "$0.00"
                      image_url = image_tag.get("src") if image_tag else None
                      set_name = set_name_tag.text.strip() if set_name_tag else "" # NEW: Get the set name text
                      
                      price_match = re.search(r'\$([\d,]+\.\d{2})', price_text)
                      price = float(price_match.group(1).replace(",", "")) if price_match else 0.0

                      # NEW: Add a condition to check if the card's set name matches our target
                      if name and