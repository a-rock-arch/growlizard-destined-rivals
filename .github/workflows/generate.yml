name: Generate All Pokémon Set Sheets

on:
  # This schedule will trigger the entire process automatically.
  schedule:
    - cron: "0 12 * * *" # Runs daily at 12:00 UTC
  # You can still run this manually for all sets if needed.
  workflow_dispatch:

jobs:
  # JOB 1: Get a list of all sets from TCGplayer
  discover-sets:
    runs-on: ubuntu-latest
    outputs:
      sets: ${{ steps.get_sets.outputs.matrix }}
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"
      - name: Install Dependencies and Browsers
        run: |
          python -m pip install --upgrade pip
          pip install beautifulsoup4 playwright
          python -m playwright install --with-deps
      - name: Discover All Sets from TCGplayer
        id: get_sets
        run: |
          python << 'EOF'
          from bs4 import BeautifulSoup
          from playwright.sync_api import sync_playwright
          import json
          import os

          # This page contains the filter with all set names
          URL = "https://www.tcgplayer.com/search/pokemon/product?productLineName=pokemon&productTypeName=Cards&view=grid"
          
          print(f"Discovering sets from: {URL}")

          html_content = ""
          try:
              with sync_playwright() as p:
                  browser = p.chromium.launch(headless=True)
                  page = browser.new_page()
                  page.goto(URL, wait_until="networkidle", timeout=60000)
                  html_content = page.content()
                  browser.close()
          except Exception as e:
              print(f"!!! FAILED to discover sets: {e}")
              exit(1)

          soup = BeautifulSoup(html_content, "html.parser")
          set_list = []
          
          # Find the dropdown/select element for the "Set" filter
          set_filter = soup.find("select", {"name": "setName"})
          if not set_filter:
              print("!!! Could not find the set filter dropdown on the page.")
              exit(1)

          # Loop through all the <option> tags within the dropdown
          for option in set_filter.find_all("option"):
              set_url_name = option.get("value")
              set_display_name = option.text.strip()
              
              # We only want real sets, not empty values or placeholders
              if set_url_name and set_display_name:
                  # Create a simple filter name from the display name (e.g., "Sword & Shield: Shrouded Fable" -> "Shrouded")
                  # This makes our existing filter logic work universally
                  filter_name = set_display_name.split(': ')[-1].split(' ')[0]
                  
                  set_list.append({
                      "set_url_name": set_url_name,
                      "set_filter_name": filter_name,
                      "set_display_name": set_display_name
                  })

          # Convert the list to a JSON string, which is how we pass it to the next job
          json_output = json.dumps(set_list)
          print(f"Discovered {len(set_list)} sets.")
          
          # This is a special syntax to set the output for the job
          with open(os.environ['GITHUB_OUTPUT'], 'a') as hf:
              print(f'matrix={json_output}', file=hf)
          EOF

  # JOB 2: Take the list of sets and generate a sheet for each one
  generate-sheets:
    needs: discover-sets
    permissions:
      contents: write
    runs-on: ubuntu-latest
    strategy:
      matrix:
        # This command takes the JSON output from the first job and uses it to create parallel jobs
        set: ${{ fromJson(needs.discover-sets.outputs.sets) }}
      fail-fast: false # Allows other jobs to continue even if one set fails

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install Dependencies and Browsers
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests beautifulsoup4 Pillow fpdf2 replicate playwright
          python -m playwright install --with-deps
          
      - name: Scrape TCGplayer Data for ${{ matrix.set.set_display_name }}
        env:
          # Use the matrix variables for the current job
          SET_URL_NAME: ${{ matrix.set.set_url_name }}
          SET_FILTER_NAME: ${{ matrix.set.set_filter_name }}
        run: |
          python << 'EOF'
          import pandas as pd
          from bs4 import BeautifulSoup
          import re
          from playwright.sync_api import sync_playwright
          import time
          import os

          set_url_name = os.environ.get('SET_URL_NAME')
          TARGET_SET_NAME = os.environ.get('SET_FILTER_NAME')
          
          BASE_URL = f"https://www.tcgplayer.com/search/pokemon/{set_url_name}?productLineName=pokemon&setName={set_url_name}&productTypeName=Cards&view=grid"
          CSV_FILENAME = f"{set_url_name}.csv"
          
          all_cards_list = []
          page_number = 1

          print(f"Starting scraper for set containing '{TARGET_SET_NAME}'...")

          with sync_playwright() as p:
              browser = p.chromium.launch(headless=True)
              page = browser.new_page(viewport={"width": 1920, "height": 1080})

              while True:
                  paginated_url = f"{BASE_URL}&page={page_number}"
                  print(f"Scraping URL: {paginated_url}")
                  
                  html_content = ""
                  try:
                      page.goto(paginated_url, wait_until="networkidle", timeout=60000)
                      time.sleep(3)
                      html_content = page.content()
                  except Exception as e:
                      print(f"Browser operation finished or failed on page {page_number}: {e}")
                      break

                  soup = BeautifulSoup(html_content, "html.parser")
                  search_results = soup.find_all("div", class_="search-result")

                  if not search_results:
                    print(f"No more search results found on page {page_number}. Ending scrape.")
                    break
                  
                  print(f"Found {len(search_results)} card results on page {page_number}. Now parsing and filtering...")

                  for card in search_results:
                      name_tag = card.find("span", class_="product-card__title")
                      price_tag = card.find("span", class_="product-card__market-price--value")
                      image_tag = card.find("img")
                      set_name_tag = card.find("h4", class_="product-card__set-name")

                      name = name_tag.text.strip() if name_tag else None
                      price_text = price_tag.text.strip() if price_tag else "$0.00"
                      image_url = image_tag.get("src") if image_tag else None
                      set_name = set_name_tag.text.strip() if set_name_tag else "" 
                      
                      price_match = re.search(r'\$([\d,]+\.\d{2})', price_text)
                      price = float(price_match.group(1).replace(",", "")) if price_match else 0.0

                      if name and image_url and "data:image/gif" not in image_url and TARGET_SET_NAME in set_name:
                          all_cards_list.append({
                              "name": name,
                              "marketPrice": price,
                              "imageUrl": image_url
                          })
                      else:
                          if name:
                              print(f"  -> Skipping card '{name}' because it's from set '{set_name}' or has a placeholder image.")
                          
                  page_number += 1
                  time.sleep(1) 

              browser.close()

          if all_cards_list:
            df = pd.DataFrame(all_cards_list)
            df.to_csv(CSV_FILENAME, index=False)
            print(f"✅ Successfully parsed and saved a total of {len(df)} cards to {CSV_FILENAME}")
          else:
            print(f"!!! FAILED to parse any card data for this set.")
            # We exit gracefully so it doesn't stop the other jobs
            exit(0)
          EOF

      - name: Download or generate card images
        env:
          REPLICATE_API_TOKEN: ${{ secrets.REPLICATE_API_TOKEN }}
          SET_URL_NAME: ${{ matrix.set.set_url_name }}
        run: |
          mkdir -p images
          python << 'EOF'
          import pandas as pd
          import requests
          import os
          import replicate
          from PIL import Image
          from io import BytesIO

          set_url_name = os.environ.get('SET_URL_NAME')
          csv_file = f"{set_url_name}.csv"
          
          # If the CSV doesn't exist (because the previous step failed), exit gracefully.
          if not os.path.exists(csv_file):
              print(f"CSV file not found for {set_url_name}. Skipping image downloads.")
              exit(0)
              
          df = pd.read_csv(csv_file)

          client = replicate.Client(api_token=os.environ["REPLICATE_API_TOKEN"])

          for _, row in df.iterrows():
              card_name = row.get("name", "unknown").replace("/", "_").replace(" ", "_").replace(":", "")
              img_path = f"images/{card_name}.jpg"
              image_url = row.get("imageUrl")

              if os.path.exists(img_path):
                  continue # Silently skip existing images to keep logs clean

              if pd.notna(image_url):
                  try:
                      img_data = requests.get(image_url, timeout=15).content
                      with open(img_path, "wb") as f:
                          f.write(img_data)
                  except Exception as e:
                      print(f"Failed official image for {card_name}: {e}")

              else: # Only generate AI art if image_url is missing
                  print(f"Generating AI art for: {card_name}")
                  prompt = f"High quality digital painting of a Pokémon-style trading card featuring {row.get('name', 'a creature')}, full art, vibrant colors, no text, fantasy background, trading card art style"
                  try:
                      output = client.run(
                          "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
                          input={"prompt": prompt, "width": 512, "height": 736}
                      )
                      img_data = requests.get(output[0], timeout=30).content
                      with open(img_path, "wb") as f:
                          f.write(img_data)
                  except Exception as e:
                      print(f"!!! AI generation failed for {card_name}: {e}")
          EOF

      - name: Generate printable PDF
        env:
          SET_URL_NAME: ${{ matrix.set.set_url_name }}
          SET_DISPLAY_NAME: ${{ matrix.set.set_display_name }}
        run: |
          python << 'EOF'
          import os
          import pandas as pd
          from fpdf import FPDF
          from datetime import datetime

          set_url_name = os.environ.get('SET_URL_NAME')
          set_display_name = os.environ.get('SET_DISPLAY_NAME')
          
          timestamp = datetime.now().strftime("%B %d, %Y at %I:%M %p EDT")
          csv_file = f"{set_url_name}.csv"
          pdf_filename = f"{set_url_name}_placeholders.pdf"
          pdf_title = f"Growlizard's {set_display_name} Print List"
          
          if not os.path.exists(csv_file):
              print(f"CSV file not found for {set_url_name}. Skipping PDF generation.")
              exit(0)
              
          df = pd.read_csv(csv_file)

          pdf = FPDF('P', 'mm', 'A4')
          pdf.set_auto_page_break(False)
          try: 
              pdf.add_font('Arial', '', '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', uni=True)
              pdf.add_font('Arial', 'B', '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', uni=True)
          except RuntimeError:
              print("Arial font not found, using helvetica.")

          card_w, card_h = 63, 88
          margin_x = 10
          margin_y = 30
          gap_x, gap_y = 5, 20

          card_data = []
          for index, row in df.iterrows():
              card_name_safe = row.get("name", "unknown").replace("/", "_").replace(" ", "_").replace(":", "")
              img_path = f"images/{card_name_safe}.jpg"
              if os.path.exists(img_path):
                  card_data.append({
                      "name": row["name"],
                      "price": row.get("marketPrice"),
                      "path": img_path
                  })

          for idx, card in enumerate(card_data):
              if idx % 6 == 0:
                  pdf.add_page()
                  try:
                      pdf.set_font("Arial", 'B', size=16)
                  except RuntimeError:
                      pdf.set_font("Helvetica", 'B', size=16)
                  pdf.set_xy(0, 10)
                  pdf.cell(0, 10, pdf_title, align='C')

                  try:
                      pdf.set_font("Arial", '', size=9)
                  except RuntimeError:
                      pdf.set_font("Helvetica", '', size=9)
                  pdf.set_xy(0, 18)
                  pdf.cell(0, 10, f"This is the current data as of {timestamp}", align='C')

              col = (idx % 3)
              row = ((idx % 6) // 3)
              x = margin_x + col * (card_w + gap_x)
              y = margin_y + row * (card_h + gap_y)

              try:
                  pdf.image(card["path"], x, y, card_w, card_h)
              except Exception as e:
                  print(f"Could not add image {card['path']} to PDF: {e}")
                  pdf.rect(x,y, card_w, card_h, 'D')
                  pdf.set_xy(x, y + card_h / 2)
                  pdf.multi_cell(card_w, 4, "Image Error", align='C')

              pdf.set_draw_color(200, 200, 200)
              pdf.rect(x, y, card_w, card_h)

              name = card['name']
              price = card['price']
              price_text = f"Current Market Price:\n${price:.2f}" if isinstance(price, (int, float)) else "Price not available"
              
              try:
                  pdf.set_font("Arial", 'B', size=8)
              except RuntimeError:
                  pdf.set_font("Helvetica", 'B', size=8)
              pdf.set_text_color(0, 0, 0)
              pdf.set_xy(x, y + card_h + 2)
              pdf.multi_cell(card_w, 4, f"{name}", align='C')

              try:
                  pdf.set_font("Arial", 'B', size=8)
              except RuntimeError:
                  pdf.set_font("Helvetica", 'B', size=8)
              pdf.set_xy(x, y + card_h + 9)
              pdf.multi_cell(card_w, 4, f"{price_text}", align='C')

          os.makedirs("printables", exist_ok=True)
          pdf.output(f"printables/{pdf_filename}")
          EOF

      - name: Commit results
        env:
          SET_URL_NAME: ${{ matrix.set.set_url_name }}
        run: |
          set_url_name=$(echo "${{ matrix.set.set_url_name }}")
          csv_file="${set_url_name}.csv"
          pdf_file="printables/${set_url_name}_placeholders.pdf"

          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          # Add the specific files for this set
          git add "$csv_file" images/ "$pdf_file"
          git commit -m "Update GrowliZard data for set: ${set_url_name}" || echo "No changes to commit"
          git push