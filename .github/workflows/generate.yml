name: Generate GrowliZard Pokémon Sheet

on:
  workflow_dispatch:
  schedule:
    - cron: "0 12 * * *"

jobs:
  build:
    permissions:
      contents: write
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install Dependencies and Browsers
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests beautifulsoup4 Pillow fpdf2 replicate playwright
          python -m playwright install --with-deps
          
      - name: Scrape TCGplayer Data
        run: |
          python << 'EOF'
          import pandas as pd
          from bs4 import BeautifulSoup
          import re
          from playwright.sync_api import sync_playwright
          import time

          BASE_URL = "https://www.tcgplayer.com/search/pokemon/sv-shrouded-fable?productLineName=pokemon&setName=sv-shrouded-fable&productTypeName=Cards&view=grid"
          TARGET_SET_NAME = "Shrouded"
          
          all_cards_list = []
          page_number = 1

          print(f"Starting scraper for set containing '{TARGET_SET_NAME}'...")

          with sync_playwright() as p:
              browser = p.chromium.launch(headless=True)
              page = browser.new_page()

              while True:
                  paginated_url = f"{BASE_URL}&page={page_number}"
                  print(f"Scraping URL: {paginated_url}")
                  
                  html_content = ""
                  try:
                      # Go to the page and wait for the basic structure to load
                      page.goto(paginated_url, wait_until="domcontentloaded", timeout=60000)
                      # Wait for at least one search result to be visible
                      page.wait_for_selector("div.search-result", timeout=30000)
                      
                      # --- THE DEFINITIVE LAZY LOADING FIX ---
                      # Instead of manually scrolling, we tell Playwright to wait until the network is quiet.
                      # This is the most reliable way to ensure all dynamic content has finished loading.
                      print("Waiting for network to be idle to ensure all images are loaded...")
                      page.wait_for_load_state('networkidle', timeout=30000)
                      
                      html_content = page.content()

                  except Exception as e:
                      print(f"Browser operation finished or failed on page {page_number}: {e}")
                      break

                  soup = BeautifulSoup(html_content, "html.parser")
                  search_results = soup.find_all("div", class_="search-result")

                  if not search_results:
                    print(f"No more search results found on page {page_number}. Ending scrape.")
                    break
                  
                  print(f"Found {len(search_results)} card results on page {page_number}. Now parsing and filtering...")

                  for card in search_results:
                      name_tag = card.find("span", class_="product-card__title")
                      price_tag = card.find("span", class_="product-card__market-price--value")
                      image_tag = card.find("img")
                      set_name_tag = card.find("h4", class_="product-card__set-name")

                      name = name_tag.text.strip() if name_tag else None
                      price_text = price_tag.text.strip() if price_tag else "$0.00"
                      image_url = image_tag.get("src") if image_tag else None
                      set_name = set_name_tag.text.strip() if set_name_tag else "" 
                      
                      price_match = re.search(r'\$([\d,]+\.\d{2})', price_text)
                      price = float(price_match.group(1).replace(",", "")) if price_match else 0.0

                      if name and image_url and "data:image/gif" not in image_url and TARGET_SET_NAME in set_name:
                          all_cards_list.append({
                              "name": name,
                              "marketPrice": price,
                              "imageUrl": image_url
                          })
                      else:
                          if name:
                              print(f"  -> Skipping card '{name}' because it's from set '{set_name}' or has a placeholder image.")
                          
                  page_number += 1
                  time.sleep(1) 

              browser.close()

          if all_cards_list:
            df = pd.DataFrame(all_cards_list)
            df.to_csv("shrouded_fable.csv", index=False)
            print(f"✅ Successfully parsed and saved a total of {len(df)} cards to shrouded_fable.csv")
          else:
            print("!!! FAILED to parse any card data from any page.")
            exit(1)
          EOF

      - name: Download or generate card images
        env:
          REPLICATE_API_TOKEN: ${{ secrets.REPLICATE_API_TOKEN }}
        run: |
          mkdir -p images
          python << 'EOF'
          import pandas as pd
          import requests
          import os
          import replicate
          from PIL import Image
          from io import BytesIO
          csv_file = "shrouded_fable.csv"
          df = pd.read_csv(csv_file)

          client = replicate.Client(api_token=os.environ["REPLICATE_API_TOKEN"])

          for _, row in df.iterrows():
              card_name = row.get("name", "unknown").replace("/", "_").replace(" ", "_").replace(":", "")
              img_path = f"images/{card_name}.jpg"
              image_url = row.get("imageUrl")

              if os.path.exists(img_path):
                  print(f"Skipping existing image: {card_name}")
                  continue

              if pd.notna(image_url):
                  try:
                      img_data = requests.get(image_url, timeout=15).content
                      with open(img_path, "wb") as f:
                          f.write(img_data)
                      print(f"Downloaded official: {card_name}")
                      continue
                  except Exception as e:
                      print(f"Failed official image for {card_name}: {e}")

              print(f"Generating AI art for: {card_name}")
              prompt = f"High quality digital painting of a Pokémon-style trading card featuring {row.get('name', 'a creature')}, full art, vibrant colors, no text, fantasy background, trading card art style"
              try:
                  output = client.run(
                      "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
                      input={"prompt": prompt, "width": 512, "height": 736}
                  )
                  img_data = requests.get(output[0], timeout=30).content
                  with open(img_path, "wb") as f:
                      f.write(img_data)
              except Exception as e:
                  print(f"!!! AI generation failed for {card_name}: {e}")
          EOF

      - name: Generate printable PDF
        run: |
          python << 'EOF'
          import os
          import pandas as pd
          from fpdf import FPDF
          df = pd.read_csv("shrouded_fable.csv")

          pdf = FPDF('P', 'mm', 'A4')
          pdf.set_auto_page_break(False)
          try: 
              pdf.add_font('Arial', '', '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', uni=True)
              pdf.add_font('Arial', 'B', '/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf', uni=True)
              pdf.set_font("Arial", 'B', size=8)
          except RuntimeError:
              print("Default font not found, using helvetica.")
              pdf.set_font("Helvetica", 'B', size=8)


          card_w, card_h = 63, 88
          margin_x, margin_y = 10, 10
          gap_x, gap_y = 5, 15

          card_data = []
          for index, row in df.iterrows():
              card_name_safe = row.get("name", "unknown").replace("/", "_").replace(" ", "_").replace(":", "")
              img_path = f"images/{card_name_safe}.jpg"
              if os.path.exists(img_path):
                  card_data.append({
                      "name": row["name"],
                      "price": row.get("marketPrice"),
                      "path": img_path
                  })

          for idx, card in enumerate(card_data):
              if idx % 9 == 0:
                  pdf.add_page()

              col = (idx % 3)
              row = ((idx % 9) // 3)
              x = margin_x + col * (card_w + gap_x)
              y = margin_y + row * (card_h + gap_y)

              try:
                  pdf.image(card["path"], x, y, card_w, card_h)
              except Exception as e:
                  print(f"Could not add image {card['path']} to PDF: {e}")
                  pdf.rect(x,y, card_w, card_h, 'D')
                  pdf.set_xy(x, y + card_h / 2)
                  pdf.multi_cell(card_w, 4, "Image Error", align='C')

              
              pdf.set_draw_color(200, 200, 200)
              pdf.rect(x, y, card_w, card_h)

              name = card['name']
              price = card['price']
              price_text = f"${price:.2f}" if isinstance(price, (int, float)) else ""
              
              try:
                  pdf.set_font("Arial", 'B', size=8)
              except RuntimeError:
                  pdf.set_font("Helvetica", 'B', size=8)
              pdf.set_text_color(0, 0, 0)
              pdf.set_xy(x, y + card_h + 2)
              pdf.multi_cell(card_w, 4, f"{name}", align='C')

              try:
                  pdf.set_font("Arial", '', size=7)
              except RuntimeError:
                  pdf.set_font("Helvetica", '', size=7)
              pdf.set_xy(x, y + card_h + 7)
              pdf.multi_cell(card_w, 4, f"{price_text}", align='C')

          os.makedirs("printables", exist_ok=True)
          pdf.output("printables/shrouded_fable_placeholders.pdf")
          EOF

      - name: Commit results
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add shrouded_fable.csv images/ printables/
          git commit -m "Update GrowliZard CSV, images (with AI), and PDF sheets" || echo "No changes to commit"
          git push